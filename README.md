# ğŸ“° News Intelligence Laboratory - RPP Retrieval System

Sistema de recuperaciÃ³n de noticias inteligente basado en embeddings semÃ¡nticos para el feed RSS de RPP PerÃº. Utiliza SentenceTransformers y ChromaDB para bÃºsquedas semÃ¡nticas avanzadas orquestadas con LangChain.

## ğŸ¯ CaracterÃ­sticas

- **IngestiÃ³n automÃ¡tica** de noticias desde RPP RSS
- **TokenizaciÃ³n** con tiktoken para anÃ¡lisis de contexto
- **Embeddings semÃ¡nticos** usando `sentence-transformers/all-MiniLM-L6-v2`
- **Base de datos vectorial** ChromaDB para bÃºsqueda por similitud
- **Pipeline modular** orquestado con LangChain (LCEL)
- **Chunking inteligente** para documentos largos
- **BÃºsqueda semÃ¡ntica** con resultados en DataFrame

## ğŸ“‹ Requisitos

- Python 3.10+
- pip o conda para gestiÃ³n de paquetes

## ğŸš€ InstalaciÃ³n

### 1. Clonar el repositorio

```bash
git clone https://github.com/tu-usuario/rpp-news-retrieval.git
cd rpp-news-retrieval
```

### 2. Crear entorno virtual (recomendado)

```bash
# Con venv
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate

# O con conda
conda create -n rpp-news python=3.11
conda activate rpp-news
```

### 3. Instalar dependencias

```bash
pip install -r requirements.txt
```

## ğŸ’» Uso

### Script Python

```python
from rpp_retrieval import RPPNewsRetriever

# Crear e inicializar el sistema
retriever = RPPNewsRetriever(max_items=50)
retriever.run_pipeline()

# Realizar consultas
results = retriever.query("Ãšltimas noticias de economÃ­a", n_results=5)
print(results)
```

### Jupyter Notebook

Abre el notebook `Task1_RPP_Retrieval.ipynb` para un tutorial paso a paso:

```bash
jupyter notebook Task1_RPP_Retrieval.ipynb
```

## ğŸ—ï¸ Arquitectura del Sistema

### Pipeline de Procesamiento

```
RSS Feed â†’ TokenizaciÃ³n â†’ Embeddings â†’ ChromaDB â†’ Retriever
```

**Paso 0: Carga de datos**
- Extrae Ãºltimas 50 noticias del RSS de RPP
- Captura: tÃ­tulo, descripciÃ³n, link, fecha

**Paso 1: TokenizaciÃ³n**
- Analiza tokens con `tiktoken` (encoding: cl100k_base)
- Determina si se requiere chunking (lÃ­mite: 256 tokens)

**Paso 2: GeneraciÃ³n de Embeddings**
- Modelo: `sentence-transformers/all-MiniLM-L6-v2`
- DimensiÃ³n: 384
- Velocidad: ~3000 tokens/segundo

**Paso 3: Almacenamiento Vectorial**
- Base de datos: ChromaDB
- Persistencia local en `./chroma_rpp`
- BÃºsqueda por similitud coseno

**Paso 4: Consultas**
- BÃºsqueda semÃ¡ntica con k-nearest neighbors
- Resultados en formato pandas DataFrame
- DeduplicaciÃ³n por tÃ­tulo

**Paso 5: OrquestaciÃ³n LangChain**
- Pipeline modular con LCEL
- Funciones reutilizables
- ConfiguraciÃ³n flexible

## ğŸ“Š Estructura del Proyecto

```
rpp-news-retrieval/
â”‚
â”œâ”€â”€ news-query_RPP-lab.ipynb    # Notebook tutorial completo
â”œâ”€â”€ requirements.txt              # Dependencias
â”œâ”€â”€ README.md                     # DocumentaciÃ³n

```

## ğŸ” Ejemplos de Consultas

```python
# Consulta sobre economÃ­a
retriever.query("Ãšltimas noticias de economÃ­a")

# Consulta sobre tecnologÃ­a
retriever.query("Noticias sobre inteligencia artificial")

# Consulta sobre polÃ­tica
retriever.query("Gobierno y elecciones en PerÃº")

# Consulta sobre deportes
retriever.query("Resultados de fÃºtbol peruano")
```

## ğŸ› ï¸ ConfiguraciÃ³n Avanzada

### Variables de Entorno

Crea un archivo `.env` para personalizar:

```bash
# RSS Feed
RPP_RSS=https://rpp.pe/rss
MAX_RSS_ITEMS=50

# ChromaDB
CHROMA_DB_DIR=./chroma_rpp
CHROMA_COLLECTION=rpp_news

# Embeddings
EMBED_MODEL_NAME=sentence-transformers/all-MiniLM-L6-v2

# TokenizaciÃ³n
MAX_TOKENS=256
OVERLAP_TOKENS=40
```

### PersonalizaciÃ³n del Pipeline

```python
from dataclasses import dataclass

@dataclass
class PipelineConfig:
    rss_url: str = "https://rpp.pe/rss"
    limit: int = 100  # MÃ¡s noticias
    max_tokens: int = 512  # Mayor contexto
    overlap: int = 50
    model_name: str = "sentence-transformers/paraphrase-multilingual-mpnet-base-v2"  # Mejor modelo

retriever = RPPNewsRetriever(config=PipelineConfig())
```

## ğŸ“ˆ Rendimiento

- **Velocidad de ingestiÃ³n**: ~50 noticias en 5-10 segundos
- **Tiempo de embeddings**: ~0.02 segundos por documento
- **Latencia de bÃºsqueda**: <100ms para 50 documentos
- **Memoria RAM**: ~500MB con modelo base

## ğŸ¤ Contribuciones

Â¡Las contribuciones son bienvenidas! Por favor:

1. Fork el proyecto
2. Crea una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

## ğŸ“ Roadmap

- [ ] Soporte para mÃºltiples fuentes RSS
- [ ] Sistema de actualizaciÃ³n incremental
- [ ] API REST con FastAPI
- [ ] Dashboard de visualizaciÃ³n con Streamlit
- [ ] ClasificaciÃ³n automÃ¡tica de categorÃ­as
- [ ] AnÃ¡lisis de sentimiento
- [ ] Sistema de recomendaciÃ³n personalizado
- [ ] Cache de consultas frecuentes
- [ ] Soporte para bÃºsqueda hÃ­brida (semÃ¡ntica + keyword)

## ğŸ› Problemas Conocidos

- ChromaDB puede requerir permisos de escritura en el directorio
- En Windows, tiktoken puede requerir Visual C++ Build Tools
- El primer uso descarga el modelo de embeddings (~80MB)

## ğŸ“š Referencias

- [LangChain Documentation](https://docs.langchain.com/)
- [ChromaDB Documentation](https://docs.trychroma.com/)
- [SentenceTransformers](https://www.sbert.net/)
- [RPP PerÃº](https://rpp.pe/)

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT. Ver archivo `LICENSE` para mÃ¡s detalles.

## ğŸ‘¨â€ğŸ’» Autor

**Tu Nombre**
- GitHub: [@tu-usuario](https://github.com/tu-usuario)
- LinkedIn: [Tu Perfil](https://linkedin.com/in/tu-perfil)

## ğŸ™ Agradecimientos

- RPP PerÃº por proporcionar el feed RSS pÃºblico
- Equipo de LangChain por el excelente framework
- Comunidad de Hugging Face por los modelos de embeddings

---

â­ Si este proyecto te fue Ãºtil, considera darle una estrella en GitHub!
